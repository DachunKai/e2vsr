{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaidc/miniconda3/envs/e2vsr/lib/python3.7/site-packages/tqdm-4.64.1-py3.7.egg/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from basicsr.utils.event_utils import *\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_file = 'datasets/CED/CED_additional_IR_filter/outdoor_shadow_1_infrared/events/000573.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(txt_file, delim_whitespace=True, header=None, names=['t', 'x', 'y', 'p'], dtype={'t': np.float64, 'x': np.int16, 'y': np.int16, 'p': np.int16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.from_numpy(data['t'].values)\n",
    "x = torch.from_numpy(data['x'].values)\n",
    "y = torch.from_numpy(data['y'].values)\n",
    "p = torch.from_numpy(data['p'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int16\n",
      "torch.int16\n",
      "torch.int16\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "print(x.dtype)\n",
    "print(y.dtype)\n",
    "print(p.dtype)\n",
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel = events_to_voxel_torch(x, y, t, p, 5, sensor_size=(260, 346))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voxel_normalization(voxel):\n",
    "    \"\"\"\n",
    "        normalize the voxel same as https://arxiv.org/abs/1912.01584 Section 3.1\n",
    "        Params:\n",
    "            voxel: torch.Tensor, shape is [num_bins, H, W]\n",
    "        \n",
    "        return:\n",
    "            normalized voxel\n",
    "    \"\"\"\n",
    "    abs_voxel, _ = torch.sort(torch.abs(voxel).view(-1, 1).squeeze(1))\n",
    "    first_non_zero_idx = torch.nonzero(abs_voxel)[0].item()\n",
    "    non_zero_voxel = abs_voxel[first_non_zero_idx:]\n",
    "    norm_idx = math.floor(non_zero_voxel.shape[0] * 0.98)\n",
    "\n",
    "    ones = torch.ones_like(voxel)\n",
    "\n",
    "    normed_voxel = torch.where(voxel >= non_zero_voxel[norm_idx], ones, voxel)\n",
    "    normed_voxel = torch.where(voxel <= -non_zero_voxel[norm_idx], -ones, voxel)\n",
    "    normed_voxel = torch.where(torch.abs(voxel) < non_zero_voxel[norm_idx], voxel / non_zero_voxel[norm_idx], voxel)\n",
    "\n",
    "    return normed_voxel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_voxel = voxel_normalization(voxel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_voxel = normed_voxel.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 260, 346)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_voxel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = 'datasets/CED/CED_additional_IR_filter/outdoor_jumping_1_infrared'\n",
    "from glob import glob\n",
    "import os.path as osp\n",
    "events_paths = sorted(glob(osp.join(input, 'events/*.txt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'datasets/CED/CED_additional_IR_filter/outdoor_jumping_1_infrared/events/000000.txt'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('datasets/CED/CED_additional_IR_filter/outdoor_jumping_1_infrared/events/000000',\n",
       " '.txt')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "osp.splitext('datasets/CED/CED_additional_IR_filter/outdoor_jumping_1_infrared/events/000000.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int('000001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_path_list = []\n",
    "h5_path_list = []\n",
    "folder_path = 'datasets/CED'\n",
    "for root, subdir, _ in os.walk(folder_path):\n",
    "    if 'images' in subdir:\n",
    "        root_path_list.append(root)\n",
    "        out = osp.join('datasets/CED_h5', osp.basename(root) + '.h5')\n",
    "        h5_path_list.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'datasets/CED_h5/simple_rabbits.h5'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5_path_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'datasets/CED/CED_simple/simple_rabbits'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_path_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathlist = []\n",
    "for root, h5 in zip(root_path_list, h5_path_list):\n",
    "    pathlist.append([root, h5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['datasets/CED/CED_simple/simple_rabbits', 'datasets/CED_h5/simple_rabbits.h5']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathlist[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hdf5 analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "path = 'datasets/CED_h5/calib_outdoor.h5'\n",
    "file = h5py.File(path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1555332068.1933038'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file['images/000000'].attrs['timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.keys()\n",
    "print(file['events'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathlist = ['datasets/CED/CED_simple/simple_rabbits', 'datasets/CED_h5/simple_rabbits.h5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaidc/miniconda3/envs/e2vsr/lib/python3.7/site-packages/tqdm-4.64.1-py3.7.egg/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from basicsr.utils.hdf5_util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package simple_rabbits.h5 finished.\n"
     ]
    }
   ],
   "source": [
    "write_h5_worker(pathlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaidc/miniconda3/envs/e2vsr/lib/python3.7/site-packages/tqdm-4.64.1-py3.7.egg/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from basicsr.utils import scandir\n",
    "import os\n",
    "from glob import glob\n",
    "import  os.path as osp\n",
    "\n",
    "h5_path = glob(osp.join('datasets/CED_h5', '*.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py\n",
    "file = h5py.File('datasets/CED_h5/driving_city_5.h5', 'r')\n",
    "len(file['voxel'].keys())\n",
    "file['voxel/004318'].attrs['is_empty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/CED/HR/CED_driving/driving_city_sun_2/events/001765.txt is empty, will write zero voxel\n",
      "datasets/CED/HR/CED_driving/driving_city_sun_2/events/001766.txt is empty, will write zero voxel\n",
      "datasets/CED/HR/CED_driving/driving_city_sun_2/events/001767.txt is empty, will write zero voxel\n",
      "datasets/CED/HR/CED_driving/driving_city_sun_2/events/001768.txt is empty, will write zero voxel\n",
      "datasets/CED/HR/CED_driving/driving_city_sun_2/events/001769.txt is empty, will write zero voxel\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2078089/3787823068.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m'datasets/CED_h5/HR/driving_city_sun_2.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m ]\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mwrite_h5_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/code/e2vsr/basicsr/utils/hdf5_util.py\u001b[0m in \u001b[0;36mwrite_h5_worker\u001b[0;34m(pathlist)\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_paths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevents_paths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevents_paths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpackage_voxel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;31m# Step 4: Add meta_info to h5 file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/e2vsr/basicsr/utils/hdf5_util.py\u001b[0m in \u001b[0;36mpackage_voxel\u001b[0;34m(self, txt_file, bins)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mvoxel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevents_to_voxel_torch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensor_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m260\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m346\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;31m# print(\"voxel.shape: \", voxel.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mnormed_voxel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvoxel_normalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvoxel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0mnp_voxel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormed_voxel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/e2vsr/basicsr/utils/event_utils.py\u001b[0m in \u001b[0;36mvoxel_normalization\u001b[0;34m(voxel)\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvoxel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvoxel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m     \u001b[0mabs_voxel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvoxel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m     \u001b[0;31m# print(\"abs_voxel.shape: \", abs_voxel.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0mfirst_non_zero_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs_voxel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from basicsr.utils.hdf5_util import write_h5_worker\n",
    "pathlist = [\n",
    "    'datasets/CED/HR/CED_driving/driving_city_sun_2',\n",
    "    'datasets/CED_h5/HR/driving_city_sun_2.h5'\n",
    "]\n",
    "write_h5_worker(pathlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaidc/miniconda3/envs/e2vsr/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package people_dynamic_wave.h5 finished.\n"
     ]
    }
   ],
   "source": [
    "from basicsr.utils.hdf5_util import write_h5_worker\n",
    "pathlist = [\n",
    "    'datasets/CED/HR/CED_people/people_dynamic_wave',\n",
    "    'datasets/CED_h5/HR/people_dynamic_wave.h5'\n",
    "]\n",
    "write_h5_worker(pathlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaidc/miniconda3/envs/e2vsr/lib/python3.7/site-packages/tqdm-4.64.1-py3.7.egg/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package simple_jenga_destroy.h5 finished.\n"
     ]
    }
   ],
   "source": [
    "from basicsr.utils.hdf5_util import write_h5_worker\n",
    "pathlist = [\n",
    "    'datasets/CED/HR/CED_simple/simple_jenga_destroy',\n",
    "    'datasets/CED_h5/HR/simple_jenga_destroy.h5'\n",
    "]\n",
    "write_h5_worker(pathlist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "txt_file = 'datasets/CED/CED_driving/driving_city_5/events/004318.txt'\n",
    "data = pd.read_csv(txt_file, delim_whitespace=True, header=None, names=['t', 'x', 'y', 'p'], dtype={'t': np.float64, 'x': np.int16, 'y': np.int16, 'p': np.int16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros((5, 260, 346))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 260, 346)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "root_path = 'datasets/CED_h5/HR'\n",
    "from glob import glob\n",
    "import os\n",
    "import os.path as osp \n",
    "h5_list = glob(osp.join(root_path, \"*.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path_list = []\n",
    "h5_path_list = []\n",
    "folder_path = 'datasets/CED/HR'\n",
    "for root, subdir, _ in os.walk(folder_path):\n",
    "    if 'images' in subdir:\n",
    "        root_path_list.append(root)\n",
    "        out = osp.join('datasets/CED_h5/HR', osp.basename(root) + '.h5')\n",
    "        h5_path_list.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['datasets/CED/HR/CED_simple/simple_rabbits', 'datasets/CED_h5/HR/simple_rabbits.h5']\n"
     ]
    }
   ],
   "source": [
    "total_path = []\n",
    "for root, h5 in zip(root_path_list, h5_path_list):\n",
    "    total_path.append([root, h5])\n",
    "print(total_path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "print(len(total_path))\n",
    "for f in total_path:\n",
    "    len_ori = len(glob(osp.join(f[0], 'events', \"*.txt\")))\n",
    "\n",
    "    file = h5py.File(f[1], 'r')\n",
    "    event_num1 = len(file['voxels'].keys())\n",
    "    # if 'voxels' in file.keys():\n",
    "    #     event_num2 = len(file['voxels'].keys())\n",
    "    # else:\n",
    "    #     event_num2 = 0\n",
    "    event_num = event_num1\n",
    "    if len_ori != event_num:\n",
    "        print(f[1], len_ori, event_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "932\n"
     ]
    }
   ],
   "source": [
    "file = h5py.File('datasets/CED_h5/simple_fruit_fast.h5', 'r')\n",
    "print(len(file['voxel'].keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cp HR/timestamp.txt to LR/timestamp.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HR_path = 'datasets/CED/HR/'\n",
    "LR_path = 'datasets/CED/LRx4'\n",
    "for root, subdir, files in os.walk(HR_path):\n",
    "    if 'timestamp.txt' in files:\n",
    "        folder = root.split(HR_path)[1]\n",
    "        src = osp.join(HR_path, folder, 'timestamp.txt')\n",
    "        dst = osp.join(LR_path, folder)\n",
    "        os.system(f\"cp -rf {src} {dst}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get hr voxel and use bicubic to downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "\n",
    "folder_path = 'datasets/CED/LR'\n",
    "root_path_list = []\n",
    "h5_hr_path_list = []\n",
    "h5_lr_path_list = []\n",
    "for root, subdir, _ in os.walk(folder_path):\n",
    "    if 'images' in subdir:\n",
    "        root_path_list.append(root)\n",
    "        h5_hr_path_list.append(osp.join('datasets/CED_h5/HR', osp.basename(root) + '.h5'))\n",
    "        h5_lr_path_list.append(osp.join('datasets/CED_h5/LR', osp.basename(root) + '.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'datasets/CED_h5/HR/simple_rabbits.h5'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5_hr_path_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "file = h5py.File(h5_hr_path_list[0], 'r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['duration', 'num_events', 'num_imgs', 'sensor_resolution', 't0', 'tk']>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.attrs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file['voxels/000000'].attrs['is_empty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 260, 346)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voxel_ex.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaidc/miniconda3/envs/e2vsr/lib/python3.7/site-packages/tqdm-4.64.1-py3.7.egg/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('./scripts/data_preparation')\n",
    "from scripts.data_preparation.pyResize import DownSample, UpSample, imresize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_lr = imresize(voxel_ex, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 130, 346)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voxel_lr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "voxel_tensor = torch.from_numpy(voxel_ex).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaidc/miniconda3/envs/e2vsr/lib/python3.7/site-packages/torch/nn/functional.py:3635: UserWarning: Default upsampling behavior when mode=bicubic is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
      "/home/kaidc/miniconda3/envs/e2vsr/lib/python3.7/site-packages/torch/nn/functional.py:3680: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  \"The default behavior for interpolate/upsample with float scale_factor changed \"\n"
     ]
    }
   ],
   "source": [
    "lr = torch.nn.functional.interpolate(input = voxel_tensor, scale_factor = 0.5, mode = 'bicubic').squeeze(0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 130, 173)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test lr h5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaidc/miniconda3/envs/e2vsr/lib/python3.7/site-packages/torch/nn/functional.py:3635: UserWarning: Default upsampling behavior when mode=bicubic is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
      "/home/kaidc/miniconda3/envs/e2vsr/lib/python3.7/site-packages/torch/nn/functional.py:3680: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  \"The default behavior for interpolate/upsample with float scale_factor changed \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package simple_carpet.h5 finished.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "from basicsr.utils.hdf5_util import *\n",
    "\n",
    "pathlist = [\n",
    "    'datasets/CED/LR/CED_simple/simple_carpet',\n",
    "    'datasets/CED_h5/HR/simple_carpet.h5',\n",
    "    'datasets/CED_h5/LR/simple_carpet.h5'\n",
    "]\n",
    "\n",
    "write_lr_h5_worker(pathlist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['duration', 'num_events', 'num_imgs', 'sensor_resolution', 't0', 'tk']>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py\n",
    "file = h5py.File('datasets/CED_h5/HR/driving_city_4.h5', 'r')\n",
    "file.attrs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 260, 346)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file['voxels/000000'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17514"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.attrs['num_events']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['people/people_dynamic_wave/images 759 (260,346,3)', 'indoors/indoors_foosball_2/images 269 (260,346,3)', 'simple/simple_wires_2/images 552 (260,346,3)', 'people/people_dynamic_dancing/images 1175 (260,346,3)', 'people/people_dynamic_jumping/images 792 (260,346,3)', 'simple/simple_fruit_fast/images 933 (260,346,3)', 'additional_IR_filter/outdoor_jumping_infrared_2/images 665 (260,346,3)', 'simple/simple_carpet_fast/images 602 (260,346,3)', 'people/people_dynamic_armroll/images 792 (260,346,3)', 'indoors/indoors_kitchen_2/images 635 (260,346,3)', 'people/people_dynamic_sitting/images 1075 (260,346,3)']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "txt_path = '/home/kaidc/code/e2vsr/basicsr/data/meta_info/CED_tmp.txt'\n",
    "\n",
    "with open(txt_path, 'r') as f:\n",
    "    str_temp = f.read().splitlines()\n",
    "    print(str_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "people_dynamic_wave 759\n"
     ]
    }
   ],
   "source": [
    "to_write = str_temp[0].split(' ')[0].split('/')[1] + ' ' + str_temp[0].split(' ')[1]\n",
    "print(to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_path = '/home/kaidc/code/e2vsr/basicsr/data/meta_info/CED_h5_test.txt'\n",
    "\n",
    "with open(txt_path, 'w') as f:\n",
    "    for i in range(len(str_temp)):\n",
    "        to_write = str_temp[i].split(' ')[0].split('/')[1] + '.h5 ' + str_temp[i].split(' ')[1] + '\\n'\n",
    "        f.write(to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_path = '/home/kaidc/code/e2vsr/basicsr/data/meta_info/CED_h5_train_2.txt'\n",
    "\n",
    "with open(txt_path, 'w') as f:\n",
    "    for i in range(len(str_temp)):\n",
    "        f.write(str_temp[i].split(' ')[0].split('/')[1] + '.h5\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "file = 'basicsr/data/meta_info/CED_h5_train.txt'\n",
    "\n",
    "keys = []\n",
    "frame_num = {}\n",
    "with open(file, 'r') as fin:\n",
    "    for line in fin:\n",
    "        name, num = line.split(' ')\n",
    "        keys.extend([f'{name}/{i:06d}' for i in range(int(num))])\n",
    "        print(osp.dirname(\"simple_flowers_infrared.h5\"))\n",
    "        frame_num[osp.dirname(name)] = num.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_num.get('simple_flowers_infrared')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_num = {}\n",
    "name = 'simple'\n",
    "num = '10'\n",
    "frame_num[name] = num\n",
    "type(frame_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = h5py.File('datasets/CED_h5/HR/people_dynamic_wave.h5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['images', 'voxels']>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = file['images/000003'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np_path = 'datasets/CED/HR/CED_people/people_dynamic_wave/images/000000.png'\n",
    "img_np = cv2.imread(np_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(img == img_np).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('tmp/img.png', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lmdb\n",
    "path = '/home/kaidc/data/VSR/CED_lmdb/train_sharp_with_val.lmdb'\n",
    "\n",
    "env = lmdb.open(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "txn = env.begin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = txn.get(str('people/people_dynamic_wave/images/000000').encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from basicsr.utils.img_util import imfrombytes\n",
    "img2 = imfrombytes(img2, float32=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99607843"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.max(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('tmp/img2.png', img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "file = h5py.File('datasets/CED_h5/LRx4/calib_fluorescent.h5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['images', 'voxels']>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['duration', 'num_events', 'num_imgs', 'sensor_resolution', 't0', 'tk']>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.attrs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 65, 86)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file['voxels/000000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('e2vsr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "80a5efb8414db1ac8a271b920b54f57b8288712ce1a871f9fa6dcbbadd404fc7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
